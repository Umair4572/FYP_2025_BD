{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models Training\n",
    "\n",
    "This notebook trains two ensemble models:\n",
    "1. **Stacking Ensemble**: Combines all base models using meta-learner (5-fold CV)\n",
    "2. **Weighted Averaging Ensemble**: Optimizes linear combination weights\n",
    "\n",
    "## Base Models:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Neural Network (Champion)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Stacking Ensemble\n",
    "\n",
    "**Method**: 5-fold cross-validation with Logistic Regression meta-learner\n",
    "\n",
    "**How it works**:\n",
    "1. Generate out-of-fold predictions from base models\n",
    "2. Train meta-learner on these predictions\n",
    "3. Combine base model outputs for final prediction\n",
    "\n",
    "**Expected runtime**: ~5-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_pipeline:Loading processed data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Stacking Ensemble training...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "STACKING ENSEMBLE MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      "1. Loading processed data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_pipeline:✓ Training data (SMOTE-balanced): (364313, 103)\n",
      "INFO:data_pipeline:✓ Validation data: (75000, 103)\n",
      "INFO:data_pipeline:✓ Test data: (100000, 103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (364313, 103)\n",
      "Validation set: (75000, 103)\n",
      "Test set: (100000, 103)\n",
      "\n",
      "2. Loading base models...\n",
      "\n",
      "================================================================================\n",
      "LOADING BASE MODELS\n",
      "================================================================================\n",
      "✓ Loaded Logistic Regression\n",
      "✓ Loaded Random Forest\n",
      "✓ Loaded XGBoost\n",
      "⚠ TensorFlow not available in this environment, skipping Neural Network model\n",
      "  (Ensemble will work with remaining models)\n",
      "\n",
      "Total models loaded: 3\n",
      "\n",
      "3. Generating meta-features...\n",
      "\n",
      "================================================================================\n",
      "GENERATING META-FEATURES WITH 5-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Base models: logistic_regression, random_forest, xgboost\n",
      "Folds: 5\n",
      "Training samples: 364,313\n",
      "\n",
      "[1/3] Processing logistic_regression...\n",
      "  Fold 1/5... Done\n",
      "  Fold 2/5... Done\n",
      "  Fold 3/5... Done\n",
      "  Fold 4/5... Done\n",
      "  Fold 5/5... Done\n",
      "  Generating predictions for validation and test sets...\n",
      "  ✓ logistic_regression meta-features complete\n",
      "\n",
      "[2/3] Processing random_forest...\n",
      "  Fold 1/5... Done\n",
      "  Fold 2/5... Done\n",
      "  Fold 3/5... Done\n",
      "  Fold 4/5... Done\n",
      "  Fold 5/5... Done\n",
      "  Generating predictions for validation and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ random_forest meta-features complete\n",
      "\n",
      "[3/3] Processing xgboost...\n",
      "  Fold 1/5... Done\n",
      "  Fold 2/5... Done\n",
      "  Fold 3/5... Done\n",
      "  Fold 4/5... Done\n",
      "  Fold 5/5... Done\n",
      "  Generating predictions for validation and test sets...\n",
      "  ✓ xgboost meta-features complete\n",
      "\n",
      "================================================================================\n",
      "META-FEATURES GENERATION COMPLETE\n",
      "================================================================================\n",
      "Train meta-features shape: (364313, 3)\n",
      "Validation meta-features shape: (75000, 3)\n",
      "Test meta-features shape: (100000, 3)\n",
      "\n",
      "4. Training meta-learner...\n",
      "\n",
      "================================================================================\n",
      "TRAINING META-LEARNER (LOGISTIC REGRESSION)\n",
      "================================================================================\n",
      "✓ Meta-learner training complete\n",
      "\n",
      "Meta-learner coefficients:\n",
      "  Logistic Regression: -1.2427\n",
      "  Random Forest: 3.3186\n",
      "  XGBoost: 4.4334\n",
      "\n",
      "5. Making predictions...\n",
      "\n",
      "6. Finding optimal threshold on validation set...\n",
      "\n",
      "Finding optimal threshold (optimizing tpr_fpr)...\n",
      "  Progress: 0/100\n",
      "  Progress: 20/100\n",
      "  Progress: 40/100\n",
      "  Progress: 60/100\n",
      "  Progress: 80/100\n",
      "Optimal threshold: 0.2363\n",
      "\n",
      "================================================================================\n",
      "VALIDATION SET RESULTS\n",
      "================================================================================\n",
      "AUC-ROC:          0.7247\n",
      "Precision:        0.3181\n",
      "Recall (TPR):     0.6950\n",
      "F1-Score:         0.4365\n",
      "FPR:              0.3708\n",
      "Specificity:      0.6292\n",
      "\n",
      "7. Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "TEST SET RESULTS\n",
      "================================================================================\n",
      "AUC-ROC:          0.7228\n",
      "Precision:        0.3188\n",
      "Recall (TPR):     0.6939\n",
      "F1-Score:         0.4369\n",
      "FPR:              0.3691\n",
      "Specificity:      0.6309\n",
      "Optimal Threshold: 0.2363\n",
      "\n",
      "8. Saving results...\n",
      "✓ Meta-learner saved to: c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\models\\stacking_ensemble_meta.pkl\n",
      "\n",
      "Saving stacking_ensemble results...\n",
      "✓ Metrics saved to: c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\results\\stacking_ensemble_metrics.pkl\n",
      "✓ Predictions saved to: c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\results\\stacking_ensemble_predictions.csv\n",
      "\n",
      "================================================================================\n",
      "STACKING ENSEMBLE TRAINING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "✓ Stacking Ensemble training complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root / 'credit_risk_fyp'))\n",
    "\n",
    "# Import and run stacking ensemble training\n",
    "from src.train_stacking_ensemble import main as train_stacking\n",
    "\n",
    "print(\"Starting Stacking Ensemble training...\\n\")\n",
    "train_stacking()\n",
    "print(\"\\n✓ Stacking Ensemble training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Weighted Averaging Ensemble\n",
    "\n",
    "**Method**: Optimize linear combination weights using scipy\n",
    "\n",
    "**How it works**:\n",
    "1. Get predictions from all base models\n",
    "2. Optimize weights to maximize AUC-ROC on validation set\n",
    "3. Apply weighted average: `final_pred = w1*LR + w2*RF + w3*XGB + w4*NN`\n",
    "\n",
    "**Expected runtime**: ~2-3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_pipeline:Loading processed data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Weighted Averaging Ensemble training...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "WEIGHTED AVERAGING ENSEMBLE MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      "1. Loading processed data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_pipeline:✓ Training data (SMOTE-balanced): (364313, 103)\n",
      "INFO:data_pipeline:✓ Validation data: (75000, 103)\n",
      "INFO:data_pipeline:✓ Test data: (100000, 103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (364313, 103)\n",
      "Validation set: (75000, 103)\n",
      "Test set: (100000, 103)\n",
      "\n",
      "2. Loading base models...\n",
      "\n",
      "================================================================================\n",
      "LOADING BASE MODELS\n",
      "================================================================================\n",
      "✓ Loaded Logistic Regression\n",
      "✓ Loaded Random Forest\n",
      "✓ Loaded XGBoost\n",
      "⚠ TensorFlow not available in this environment, skipping Neural Network model\n",
      "  (Ensemble will work with remaining models)\n",
      "\n",
      "Total models loaded: 3\n",
      "\n",
      "3. Getting base model predictions...\n",
      "\n",
      "================================================================================\n",
      "GETTING BASE MODEL PREDICTIONS\n",
      "================================================================================\n",
      "Base models: logistic_regression, random_forest, xgboost\n",
      "\n",
      "[1/3] logistic_regression...\n",
      "  ✓ Predictions shape: val=(75000,), test=(100000,)\n",
      "\n",
      "[2/3] random_forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Predictions shape: val=(75000,), test=(100000,)\n",
      "\n",
      "[3/3] xgboost...\n",
      "  ✓ Predictions shape: val=(75000,), test=(100000,)\n",
      "\n",
      "================================================================================\n",
      "BASE PREDICTIONS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "4. Optimizing ensemble weights...\n",
      "\n",
      "================================================================================\n",
      "OPTIMIZING WEIGHTS (metric: AUC_ROC)\n",
      "================================================================================\n",
      "Initial weights (equal): [0.33333333 0.33333333 0.33333333]\n",
      "Running optimization...\n",
      "\n",
      "================================================================================\n",
      "OPTIMIZATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "Optimized weights:\n",
      "  Logistic Regression: 0.0000 (0.0%)\n",
      "  Random Forest: 0.4483 (44.8%)\n",
      "  XGBoost: 0.5517 (55.2%)\n",
      "\n",
      "Sum of weights: 1.000000\n",
      "Optimization score: 0.7247\n",
      "\n",
      "5. Making weighted predictions...\n",
      "\n",
      "6. Finding optimal threshold on validation set...\n",
      "\n",
      "Finding optimal threshold (optimizing tpr_fpr)...\n",
      "  Progress: 0/100\n",
      "  Progress: 20/100\n",
      "  Progress: 40/100\n",
      "  Progress: 60/100\n",
      "  Progress: 80/100\n",
      "Optimal threshold: 0.3696\n",
      "\n",
      "================================================================================\n",
      "VALIDATION SET RESULTS\n",
      "================================================================================\n",
      "AUC-ROC:          0.7247\n",
      "Precision:        0.3226\n",
      "Recall (TPR):     0.6788\n",
      "F1-Score:         0.4374\n",
      "FPR:              0.3548\n",
      "Specificity:      0.6452\n",
      "\n",
      "7. Evaluating on test set...\n",
      "\n",
      "================================================================================\n",
      "TEST SET RESULTS\n",
      "================================================================================\n",
      "AUC-ROC:          0.7227\n",
      "Precision:        0.3236\n",
      "Recall (TPR):     0.6785\n",
      "F1-Score:         0.4382\n",
      "FPR:              0.3531\n",
      "Specificity:      0.6469\n",
      "Optimal Threshold: 0.3696\n",
      "\n",
      "8. Saving results...\n",
      "✓ Weights saved to: c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\models\\weighted_ensemble_weights.pkl\n",
      "\n",
      "Saving weighted_ensemble results...\n",
      "✓ Metrics saved to: c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\results\\weighted_ensemble_metrics.pkl\n",
      "✓ Predictions saved to: c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\results\\weighted_ensemble_predictions.csv\n",
      "\n",
      "================================================================================\n",
      "WEIGHTED ENSEMBLE TRAINING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "✓ Weighted Averaging Ensemble training complete!\n"
     ]
    }
   ],
   "source": [
    "# Import and run weighted ensemble training\n",
    "from src.train_weighted_ensemble import main as train_weighted\n",
    "\n",
    "print(\"Starting Weighted Averaging Ensemble training...\\n\")\n",
    "train_weighted()\n",
    "print(\"\\n✓ Weighted Averaging Ensemble training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training Complete!\n",
    "\n",
    "Both ensemble models have been trained and results saved to:\n",
    "- `credit_risk_fyp/results/stacking_ensemble_metrics.pkl`\n",
    "- `credit_risk_fyp/results/weighted_ensemble_metrics.pkl`\n",
    "\n",
    "**Next Step**: Run `model_comparison.ipynb` to compare all 6 models:\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. Neural Network\n",
    "5. Stacking Ensemble\n",
    "6. Weighted Averaging Ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
